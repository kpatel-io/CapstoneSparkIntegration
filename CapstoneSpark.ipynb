{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ab202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f2cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c806983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/48.5M [00:00<?, ?B/s]\n",
      "  2%|2         | 1.00M/48.5M [00:00<00:05, 9.88MB/s]\n",
      "  4%|4         | 2.00M/48.5M [00:02<00:58, 836kB/s] \n",
      "  6%|6         | 3.00M/48.5M [00:02<00:35, 1.33MB/s]\n",
      "  8%|8         | 4.00M/48.5M [00:03<00:40, 1.14MB/s]\n",
      " 10%|#         | 5.00M/48.5M [00:04<00:45, 995kB/s] \n",
      " 12%|#2        | 6.00M/48.5M [00:05<00:36, 1.23MB/s]\n",
      " 14%|#4        | 7.00M/48.5M [00:05<00:26, 1.63MB/s]\n",
      " 16%|#6        | 8.00M/48.5M [00:05<00:19, 2.19MB/s]\n",
      " 19%|#8        | 9.00M/48.5M [00:05<00:14, 2.88MB/s]\n",
      " 23%|##2       | 11.0M/48.5M [00:05<00:08, 4.48MB/s]\n",
      " 27%|##6       | 13.0M/48.5M [00:06<00:06, 6.17MB/s]\n",
      " 31%|###       | 15.0M/48.5M [00:06<00:04, 8.20MB/s]\n",
      " 37%|###7      | 18.0M/48.5M [00:06<00:02, 11.4MB/s]\n",
      " 43%|####3     | 21.0M/48.5M [00:06<00:02, 14.2MB/s]\n",
      " 49%|####9     | 24.0M/48.5M [00:06<00:01, 16.3MB/s]\n",
      " 56%|#####5    | 27.0M/48.5M [00:06<00:01, 17.6MB/s]\n",
      " 62%|######1   | 30.0M/48.5M [00:06<00:01, 18.5MB/s]\n",
      " 66%|######5   | 32.0M/48.5M [00:06<00:00, 19.0MB/s]\n",
      " 72%|#######2  | 35.0M/48.5M [00:07<00:00, 19.9MB/s]\n",
      " 78%|#######8  | 38.0M/48.5M [00:07<00:00, 20.4MB/s]\n",
      " 85%|########4 | 41.0M/48.5M [00:07<00:00, 20.8MB/s]\n",
      " 91%|######### | 44.0M/48.5M [00:07<00:00, 21.5MB/s]\n",
      " 97%|#########6| 47.0M/48.5M [00:07<00:00, 20.6MB/s]\n",
      "100%|##########| 48.5M/48.5M [00:07<00:00, 6.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading traffic-violations-in-usa.zip to C:\\Users\\KEVAL\\Desktop\\CapstoneSparkIntegration\n",
      "\n",
      "downloaded data\n",
      "unzipped the data\n"
     ]
    }
   ],
   "source": [
    "#Download Dataset and Extract on local Machine\n",
    "!kaggle datasets download --force -d felix4guti/traffic-violations-in-usa\n",
    "print('downloaded data')\n",
    "with zipfile.ZipFile(\"./{}.zip\".format(\"traffic-violations-in-usa\"),\"r\") as z:\n",
    "    z.extractall(\".\")\n",
    "print('unzipped the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d62fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark \n",
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1664b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ecd074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data.csv into a RDD to dataframe\n",
    "#source_df = sc.textFile(r\"C:/Users/KEVAL/Desktop/CapstoneSparkIntegration/Traffic_Violations.csv\")\n",
    "\n",
    "source_df = spark.read.load(r'C:/Users/KEVAL/Desktop/CapstoneSparkIntegration/Traffic_Violations.csv', format =\"csv\", sep=\",\",inferSchema=True, header = True)\n",
    "\n",
    "source_df.printSchema()\n",
    "#source_df.show()\n",
    "\n",
    "#source_df.toDF().write.mode('overwrite').parquet(r\"C:/Users/KEVAL/Desktop/CapstoneSparkIntegration/ParquetFiles/Violations.parquet\")\n",
    "#source_df = spark.read.format(r\"C:\\Users\\KEVAL\\Desktop\\CapstoneSparkIntegration\\Traffic_Violations.csv\")\n",
    "#source_df.toDF().parquet(r\"C:\\Users\\KEVAL\\Desktop\\CapstoneSparkIntegration\\ParquetFiles\\Violations.parquet\")\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "#Replace space \" \" with underscore\"_\"\n",
    "source_df = source_df.select([\n",
    "    col(c).alias(c.replace(\" \",\"_\"))\n",
    "    for c in source_df.columns\n",
    "])\n",
    "source_df.show()\n",
    "#source_df.write.parquet(r\"C:/Users/KEVAL/Desktop/CapstoneSparkIntegration/ParquetFiles/Violations_traffic.parquet\")\n",
    "source_df.write.mode('overwrite').parquet(r\"C:/Users/KEVAL/Desktop/CapstoneSparkIntegration/ParquetFiles/Violations.parquet\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
